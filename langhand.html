<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autonomous Site-Analysis Agent Strategy</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Chosen Palette: Agent Blue -->
    <!-- Application Structure Plan: The application is designed as a single-page interactive report with a fixed sidebar navigation for easy access to different strategic sections. The structure is thematic: 1. A high-level overview answering the user's key questions. 2. A detailed, multi-stage architecture diagram built with HTML/CSS to visualize the agent's workflow. 3. An interactive 'Tool Roles' section using clickable tabs to explain the function of each technology. 4. A 'Data Schema Explorer' to clarify the final output structure. This design was chosen to break down a complex, multi-stage technical strategy into digestible, non-linear sections, allowing a user to either follow the flow sequentially or jump directly to the part most relevant to them, enhancing usability and understanding. -->
    <!-- Visualization & Content Choices: Report Info: Agent workflow -> Goal: Organize & Explain -> Viz/Presentation: CSS Flexbox/Grid Diagram -> Interaction: None, static visual -> Justification: A static, custom-styled diagram provides more clarity and control for representing a multi-step process with decision points than a data-driven chart would. | Report Info: Tech stack roles -> Goal: Inform -> Viz/Presentation: Tabbed Interface -> Interaction: Click tabs to reveal content -> Justification: Tabs manage complexity by showing one piece of information at a time, preventing cognitive overload and improving focus. | Report Info: JSON Output -> Goal: Inform -> Viz/Presentation: Styled pre-formatted text blocks -> Interaction: None -> Justification: Directly presenting the code-like structure is the clearest way to explain the data schema. All choices avoid SVG/Mermaid as required. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        .active-nav {
            background-color: #e0f2fe;
            color: #0c4a6e;
            font-weight: 600;
        }
        .tab.active {
            border-bottom-color: #0ea5e9;
            color: #0369a1;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        .arrow {
            position: relative;
            width: 100%;
            height: 30px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .arrow::before {
            content: '';
            position: absolute;
            width: 2px;
            height: 100%;
            background-color: #9ca3af;
        }
        .arrow::after {
            content: '';
            position: absolute;
            bottom: 0;
            border: solid #9ca3af;
            border-width: 0 2px 2px 0;
            display: inline-block;
            padding: 4px;
            transform: rotate(45deg);
        }
    </style>
</head>
<body class="bg-slate-50 text-slate-800">

    <div class="flex min-h-screen">
        <!-- Sidebar Navigation -->
        <aside class="w-64 bg-white border-r border-slate-200 p-6 sticky top-0 h-screen hidden lg:block">
            <h1 class="text-xl font-bold text-sky-800 mb-8">Agent Strategy</h1>
            <nav id="desktop-nav">
                <ul class="space-y-2">
                    <li><a href="#overview" class="block py-2 px-3 rounded-md text-slate-600 hover:bg-slate-100">Overview</a></li>
                    <li><a href="#architecture" class="block py-2 px-3 rounded-md text-slate-600 hover:bg-slate-100">Agent Architecture</a></li>
                    <li><a href="#roles" class="block py-2 px-3 rounded-md text-slate-600 hover:bg-slate-100">Tool Roles</a></li>
                    <li><a href="#schema" class="block py-2 px-3 rounded-md text-slate-600 hover:bg-slate-100">Data Schema</a></li>
                    <li><a href="#ethics" class="block py-2 px-3 rounded-md text-slate-600 hover:bg-slate-100">Ethics & Quality</a></li>
                </ul>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 p-4 sm:p-6 md:p-10">
            <div class="max-w-4xl mx-auto">
                
                <section id="overview" class="mb-16 scroll-mt-20">
                    <h2 class="text-3xl font-bold text-slate-900 mb-4">Autonomous Site-Analysis Agent</h2>
                    <p class="text-lg text-slate-600 mb-6">This document outlines a comprehensive strategy for building an autonomous agent to crawl, analyze, and produce a structured, non-code "clone" of a target website. The agent leverages a modern stack to deconstruct web pages into meaningful data.</p>
                    
                    <div class="bg-sky-100 border-l-4 border-sky-500 text-sky-800 p-4 rounded-r-lg">
                        <h3 class="font-bold mb-2">Is LangGraph a Core Ingredient?</h3>
                        <p>Yes, LangGraph is the essential "brain" of the operation. While Browserbase acts as the "eyes and hands" to interact with websites and Stagehand ensures structured data output, LangGraph serves as the orchestrator. It manages the complex, multi-step, and stateful process of crawling. A simple script would be brittle; LangGraph provides the robustness, error-handling (e.g., retries, dead ends), and cyclical logic required for a truly autonomous agent that can navigate the unpredictability of the web.</p>
                    </div>
                </section>

                <section id="architecture" class="mb-16 scroll-mt-20">
                    <h2 class="text-3xl font-bold text-slate-900 mb-6">Agent Architecture: A State-Driven Approach</h2>
                    <p class="text-slate-600 mb-8">The agent operates as a state machine managed by LangGraph. Each node in the graph represents a distinct task, ensuring a modular and resilient workflow. The process flows from initial checks through a main crawling loop and concludes with synthesis and output generation.</p>

                    <div class="space-y-4">
                        <!-- Step 1 -->
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <span class="text-sm font-semibold text-sky-600">STAGE 1</span>
                            <h3 class="text-xl font-bold mt-1 mb-2">Initialization & Pre-flight Checks</h3>
                            <p class="text-slate-600">The agent starts by verifying its authorization to crawl the target site. This is a critical first step to ensure ethical operation.</p>
                            <ul class="mt-4 list-disc list-inside text-slate-600 space-y-1">
                                <li><strong>Input:</strong> Target Root URL, Crawl Depth</li>
                                <li><strong>Action:</strong> Fetch and parse `robots.txt` and Terms of Service.</li>
                                <li><strong>Decision:</strong> If scraping is disallowed, the agent halts and reports. Otherwise, it proceeds to the crawl loop.</li>
                            </ul>
                        </div>
                        <div class="arrow"></div>
                        <!-- Step 2 -->
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <span class="text-sm font-semibold text-sky-600">STAGE 2</span>
                            <h3 class="text-xl font-bold mt-1 mb-2">Crawl & Scrape Loop (LangGraph State Machine)</h3>
                            <p class="text-slate-600">This is the core of the agent's operation, cycling through URLs to fetch, analyze, and process pages until the queue is empty or the depth limit is reached.</p>
                            <div class="mt-4 border-t border-slate-200 pt-4 grid md:grid-cols-2 gap-4">
                                <div>
                                    <h4 class="font-semibold">1. Fetch Next URL</h4>
                                    <p class="text-sm text-slate-500">Dequeue a URL from the `urls_to_visit` list.</p>
                                </div>
                                <div>
                                    <h4 class="font-semibold">2. Render Page with Browserbase</h4>
                                    <p class="text-sm text-slate-500">Load the page in a headless browser to capture the fully rendered DOM, assets, and an optional screenshot.</p>
                                </div>
                                <div>
                                    <h4 class="font-semibold">3. Analyze Content with Stagehand</h4>
                                    <p class="text-sm text-slate-500">Pass the rendered HTML to an LLM via Stagehand, which uses a predefined schema to extract structured content, annotations, assets, and links.</p>
                                </div>
                                <div>
                                    <h4 class="font-semibold">4. Update State & Enqueue Links</h4>
                                    <p class="text-sm text-slate-500">Add extracted data to the main results and add newly discovered internal URLs to the crawl queue.</p>
                                </div>
                            </div>
                        </div>
                        <div class="arrow"></div>
                        <!-- Step 3 -->
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <span class="text-sm font-semibold text-sky-600">STAGE 3</span>
                            <h3 class="text-xl font-bold mt-1 mb-2">Post-Crawl Synthesis</h3>
                            <p class="text-slate-600">Once the crawl is complete, the agent analyzes the collected data holistically to identify site-wide patterns and generate high-level insights.</p>
                             <ul class="mt-4 list-disc list-inside text-slate-600 space-y-1">
                                <li><strong>Identify Patterns:</strong> Detect consistent headers, footers, and navigation elements across pages.</li>
                                <li><strong>Deduce Templates:</strong> Group pages with similar layouts into guessed templates (e.g., "Product Page," "Article").</li>
                                <li><strong>Generate Summary:</strong> Create a human-readable executive summary of the site's structure.</li>
                            </ul>
                        </div>
                        <div class="arrow"></div>
                        <!-- Step 4 -->
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <span class="text-sm font-semibold text-green-600">FINAL STAGE</span>
                            <h3 class="text-xl font-bold mt-1 mb-2">Output Generation</h3>
                            <p class="text-slate-600">The final step is to assemble all collected and synthesized data into the specified deliverable formats.</p>
                            <ul class="mt-4 list-disc list-inside text-slate-600 space-y-1">
                                <li><strong>JSON Package:</strong> A single, comprehensive JSON file containing all structured data.</li>
                                <li><strong>Markdown README:</strong> A summary document with the sitemap, key findings, and any warnings.</li>
                            </ul>
                        </div>
                    </div>
                </section>

                <section id="roles" class="mb-16 scroll-mt-20">
                    <h2 class="text-3xl font-bold text-slate-900 mb-6">Tool Roles</h2>
                    <p class="text-slate-600 mb-8">Each tool in the stack plays a specialized and critical role in the agent's success. Together, they form a powerful pipeline for web analysis.</p>
                    
                    <div>
                        <div class="border-b border-slate-200">
                            <nav class="flex space-x-4" id="tabs">
                                <button data-target="langgraph" class="tab active py-2 px-1 text-slate-600 border-b-2 border-transparent hover:border-slate-300">LangGraph</button>
                                <button data-target="browserbase" class="tab py-2 px-1 text-slate-600 border-b-2 border-transparent hover:border-slate-300">Browserbase</button>
                                <button data-target="stagehand" class="tab py-2 px-1 text-slate-600 border-b-2 border-transparent hover:border-slate-300">Stagehand</button>
                            </nav>
                        </div>
                        <div class="py-6">
                            <div id="langgraph-content" class="tab-content active">
                                <h3 class="text-2xl font-bold mb-2">LangGraph: The Brain & Orchestrator</h3>
                                <p class="text-slate-600">LangGraph defines the workflow and logic of the agent. It connects all the pieces into a coherent, fault-tolerant system. Its graph-based structure is ideal for the cyclical and conditional nature of web crawling, allowing for loops, error handling, and state management that would be difficult to manage in a linear script.</p>
                            </div>
                            <div id="browserbase-content" class="tab-content">
                                <h3 class="text-2xl font-bold mb-2">Browserbase: The Eyes & Hands</h3>
                                <p class="text-slate-600">Browserbase provides the core web interaction capabilities. It runs fleets of headless browsers, allowing the agent to load pages just as a user would. This is critical for capturing content generated by JavaScript, taking accurate screenshots, and extracting the final, rendered state of a page's DOM for analysis.</p>
                            </div>
                            <div id="stagehand-content" class="tab-content">
                                <h3 class="text-2xl font-bold mb-2">Stagehand: The Structured Parser</h3>
                                <p class="text-slate-600">Stagehand bridges the gap between unstructured web content (HTML) and the structured data the agent needs. By defining a clear JSON schema, we can instruct an LLM to reliably extract specific information—like hero sections, navigation links, or form elements—and ensure the output is always in a predictable, machine-readable format.</p>
                            </div>
                        </div>
                    </div>
                </section>

                <section id="schema" class="mb-16 scroll-mt-20">
                    <h2 class="text-3xl font-bold text-slate-900 mb-6">Data Schema Explorer</h2>
                    <p class="text-slate-600 mb-8">The agent's primary output is a single JSON file. This structured format captures the entire site analysis in a predictable way. Below is an example of the key objects within the final JSON package.</p>
                    <div class="space-y-4">
                        <div class="bg-slate-800 text-slate-200 p-4 rounded-lg">
                            <h4 class="font-mono text-lg text-cyan-400">metadata: { ... }</h4>
                            <pre class="text-sm overflow-x-auto"><code class="language-json">{
  "site_url": "https://example.com",
  "crawled_at": "2025-09-18T20:35:00Z",
  "pages_crawled": 52,
  "crawl_depth": 4,
  "robots_status": "Allowed"
}</code></pre>
                        </div>
                         <div class="bg-slate-800 text-slate-200 p-4 rounded-lg">
                            <h4 class="font-mono text-lg text-cyan-400">pages[0].structured_content[0]: { ... }</h4>
                            <pre class="text-sm overflow-x-auto"><code class="language-json">{
  "block_id": "p-001-hero",
  "block_type": "hero",
  "text": "Grow your business with AI",
  "attributes": {
    "tag": "div.hero",
    "css_classes": ["hero", "hero--large"],
    "image_src": "/images/hero-1.jpg",
    "cta": [{"text": "Get started", "href": "/signup"}]
  }
}</code></pre>
                        </div>
                         <div class="bg-slate-800 text-slate-200 p-4 rounded-lg">
                            <h4 class="font-mono text-lg text-cyan-400">pages[0].annotations[0]: { ... }</h4>
                            <pre class="text-sm overflow-x-auto"><code class="language-json">{
  "selector": "body > header.main-header",
  "label": "[header]",
  "confidence": 0.98
}</code></pre>
                        </div>
                    </div>
                </section>
                
                <section id="ethics" class="scroll-mt-20">
                    <h2 class="text-3xl font-bold text-slate-900 mb-6">Ethics & Quality Checks</h2>
                    <p class="text-slate-600 mb-8">Responsible operation is paramount. The agent is designed with safeguards to respect website owners and ensure the quality and accuracy of its analysis.</p>
                     <div class="grid md:grid-cols-2 gap-6">
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <h3 class="text-xl font-bold mb-2">Ethical Constraints</h3>
                             <ul class="list-disc list-inside text-slate-600 space-y-2">
                                <li><strong>Robots.txt Adherence:</strong> The agent will always fetch and obey the rules defined in `robots.txt` before proceeding.</li>
                                <li><strong>Terms of Service:</strong> It will perform a best-effort scan for terms forbidding automated access and will halt if found.</li>
                                <li><strong>Rate Limiting:</strong> A polite crawling speed is enforced to avoid overwhelming the target server.</li>
                                 <li><strong>Copyright Flagging:</strong> Content identified as potentially paywalled or explicitly copyrighted will be flagged, and only a summary will be stored.</li>
                            </ul>
                        </div>
                        <div class="bg-white p-6 rounded-lg shadow-sm border border-slate-200">
                            <h3 class="text-xl font-bold mb-2">Quality Validations</h3>
                             <ul class="list-disc list-inside text-slate-600 space-y-2">
                                <li><strong>URL Integrity:</strong> The final sitemap is checked to ensure all listed URLs returned a success (2xx/3xx) status code.</li>
                                <li><strong>Content Match:</strong> A random subset of pages is re-rendered to validate that the captured text has a high degree of similarity with a live version.</li>
                                <li><strong>Component Evidence:</strong> Any guesses for the `component_inventory` must be supported by evidence, such as specific script filenames or unique CSS class patterns.</li>
                            </ul>
                        </div>
                    </div>
                </section>

            </div>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const tabs = document.querySelectorAll('#tabs .tab');
            const tabContents = document.querySelectorAll('.tab-content');

            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    const target = tab.dataset.target;

                    tabs.forEach(t => t.classList.remove('active'));
                    tab.classList.add('active');

                    tabContents.forEach(content => {
                        content.classList.remove('active');
                        if (content.id === `${target}-content`) {
                            content.classList.add('active');
                        }
                    });
                });
            });
            
            const navLinks = document.querySelectorAll('#desktop-nav a');
            const sections = document.querySelectorAll('main section');

            function changeNav() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}
                
                navLinks.forEach((link) => link.classList.remove('active-nav'));
                if (navLinks[index]) {
                   navLinks[index].classList.add('active-nav');
                }
            }

            changeNav();
            window.addEventListener('scroll', changeNav);
        });
    </script>
</body>
</html>
